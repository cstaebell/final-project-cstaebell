[
  {
    "objectID": "data/Readme.html",
    "href": "data/Readme.html",
    "title": "Data Folder",
    "section": "",
    "text": "Data Folder\nPlace any data needed by your analysis in this folder. Please do not store large files here. Then read in any data using the ‘data’ path. For example, read_csv(\"data/data.csv\")."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Starry Night?",
    "section": "",
    "text": "Electric lights have benefited society immensely since their invention in 1879. Modern work, recreation, and transportation are made possible largely due to artificial lighting. However, when artificial outdoor lighting becomes inefficient and unnecessary, it is known as light pollution, with negative impacts on both wildlife and humans (Chepesiuk 2009).\nConcerns about the effects of light pollution on astronomy led to the 1988 formation of the nonprofit now known as DarkSky International (Hunter 2023). Since then, DarkSky has grown into a recognized global authority on light pollution with a mission to safeguard communities and wildlife against light pollution (DarkSky 2025a). The organization’s International Dark Sky Places program allows communities, parks, and protected areas to seek certification for efforts to preserve and protect their dark skies (DarkSky 2025b).\nNotably, Flagstaff, Arizona was the first International Dark Sky Place, designated in 2001. As a hub for astronomical observation, the city has been a leader in outdoor lighting policy since 1958 (Darksky 2015). Other cities, particularly those in the western US, have also recognized the need for measures to combat light pollution, and have achieved DarkSky certification. While certification is certainly not necessary for communities to implement outdoor lighting ordinances and other measures to curb light pollution, it is an indicator of places that have made dark sky conservation a priority.\nThis project aims to explore trends in nighttime light levels first from a national contiguous US perspective, and through more detailed case studies of individual cities."
  },
  {
    "objectID": "index.html#download-and-clean-all-required-data",
    "href": "index.html#download-and-clean-all-required-data",
    "title": "Starry Night?",
    "section": "Download and clean all required data",
    "text": "Download and clean all required data\nThe nighttime lights raster and extracted values for the entire US take a while to download, so I had planned to include the following code which writes the data to files that can be loaded individually. But the files are somewhat large and I broke my original github build when I committed the update containing them. (There was probably another issue causing the build failure but the files are larger than recommended for storage in the data folder, anyway.)\n\n# Download and save CONUS black marble data. \n\n# Define region of interest\nnonconus &lt;- c(\"Guam\", \"Hawaii\", \"Alaska\",\n              \"Commonwealth of the Northern Mariana Islands\",\n              \"United States Virgin Islands\", \"American Samoa\", \"Puerto Rico\")\nstates_sf &lt;- states() |&gt;\n  filter(!NAME %in% nonconus) |&gt;\n  select(NAME, geometry) |&gt;\n  st_transform(crs = \"epsg:4326\") # EPSG:4326 for compatibility with black marble\n\n# Nighttime lights annual data (black marble)\nbm_annual &lt;- bm_raster(roi_sf = states_sf,\n                      product_id = \"VNP46A4\",\n                      date = c(2012,2024),\n                      bearer = nasa_bearer_token) |&gt; terra::mask(states_sf)\n\nwriteRaster(bm_annual, filename = \"data/blackmarble_us_2012_2024.tif\")\n\n# Create log transformed version for mapping\napp(bm_annual, fun = log1p, filename = \"data/log_blackmarble_us_2012_2024.tif\", overwrite = TRUE)\n\n# values\nntl_2012_2024 &lt;- bm_extract(roi_sf = states_sf,\n                         product_id = \"VNP46A4\",\n                         date = 2012:2024, \n                         bearer = nasa_bearer_token)\n\nwrite.csv(ntl_2012_2024, \"data/bm_vals_states_2012to2024.csv\", row.names = FALSE)\n\nThe following code was used to generate a national nighttime lights figure (embedded below, saved from previous). Further national analysis was planned, but I need to figure out how to store and access the data.\n\nus_2024 &lt;- ggplot() +\n  geom_spatraster(data = log_bm_us[[2]]) + \n  scale_fill_gradient2(low = \"black\",\n                       mid = \"yellow\", \n                       high = \"red\",\n                       midpoint = 4.5,\n                       na.value = \"transparent\") +\n  labs(title = \"Nighttime Lights: 2024\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"none\")\n  \n\nlog_diff_us &lt;- ggplot() +\n  geom_spatraster(data = us_log_diff, aes(fill = log_diff)) + \n  scale_fill_gradient2(low = \"blue\",\n                       mid = \"gray95\",\n                       high = \"red\",\n                       midpoint = 0,\n                       na.value = \"transparent\") +\n  labs(title = \"Nighttime Lights Log Difference between 2024 and 2012\",\n       fill = \"Log Difference\", subtitle = NULL) +\n  coord_sf() +\n  theme_void()\n\nus_ntl &lt;- us_2024 / log_diff_us \n\n\nFor case study analyses, population data and local geographies were downloaded from the US Census.\n\n# Download population data\nus_pop &lt;- get_acs(geograph = \"place\", state = NULL, \n                  variables = \"B01003_001\", key = census_api_key)\n\naz_pop &lt;- get_acs(geography = \"place\", state = \"AZ\", \n                         variables = \"B01003_001\", key = census_api_key)\n\nil_pop &lt;- get_acs(geography = \"place\", state = \"IL\", \n                         variables = \"B01003_001\", key = census_api_key)\n\ntx_pop &lt;- get_acs(geography = \"place\", state = \"TX\", \n                         variables = \"B01003_001\", key = census_api_key)\n\n# Download local geographies: selected Dark Sky Places\nflagstaff &lt;- places(state = \"AZ\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Flagstaff\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\nhomerglen &lt;- places(state = \"IL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Homer Glen\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\nbeecave &lt;- places(state = \"TX\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Bee Cave\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\nCities of similar population size were found for each selected Dark-Sky community. The city selection process focused on states that do not have laws regarding light pollution or dark sky protection, as compiled by Schultz (2022).\n\n# Find suitable comparison cities\nflagstaff_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (flagstaff$estimate - 0.01*flagstaff$estimate) \n                                & estimate &lt;= (flagstaff$estimate + 0.01*flagstaff$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\nhomerglen_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (homerglen$estimate - 0.005*homerglen$estimate) \n                                & estimate &lt;= (homerglen$estimate + 0.005*homerglen$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\nbeecave_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (beecave$estimate - 0.005*beecave$estimate) \n                                & estimate &lt;= (beecave$estimate + 0.005*beecave$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\n# Download/process comparison city data\n # Flagstaff counterpart\nscranton &lt;- places(state = \"PA\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Scranton\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\n # Homer Glen counterpart\nbelvidere &lt;- places(state = \"IL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Belvidere\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\n # Bee Cave counterpart\nclanton &lt;- places(state = \"AL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Clanton\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\nThere are issues downloading nighttime lights data in real time when rendering. So, I made small raster files of the downloaded black marble data.\n\nflagstaff_bm &lt;- bm_raster(roi_sf = flagstaff,\n                      product_id = \"VNP46A4\",\n                      date = c(2012,2016,2020,2024),\n                      bearer = nasa_bearer_token) |&gt; terra::mask(flagstaff)\n\nwriteRaster(flagstaff_bm, filename = \"data/flagstaff_bm.tif\")\n\nscranton_bm &lt;- bm_raster(roi_sf = scranton,\n                      product_id = \"VNP46A4\",\n                      date = c(2012,2016,2020,2024),\n                      bearer = nasa_bearer_token) |&gt; terra::mask(scranton)\n\nwriteRaster(scranton_bm, filename = \"data/scranton_bm.tif\")\n\n\nflagstaff_bm_rast &lt;- rast(\"data/flagstaff_bm.tif\")\nscranton_bm_rast &lt;- rast(\"data/scranton_bm.tif\")\n\nplot(flagstaff_bm_rast)\n\n\n\n\n\n\n\nplot(scranton_bm_rast)\n\n\n\n\n\n\n\n# calculate mean normalized radiance\nflagstaff_area_km &lt;- flagstaff$ALAND / 1000^2\nscranton_area_km &lt;- scranton$ALAND / 1000^2\n\nscranton_rad &lt;- data.frame(values(scranton_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"sc_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         sc_a_norm_mean = sc_mean / scranton_area_km)\n\nflagstaff_rad &lt;- data.frame(values(flagstaff_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"fs_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         fs_a_norm_mean = fs_mean / flagstaff_area_km)\n\nflagstaff_comp_df &lt;- flagstaff_rad |&gt;\n  select(-fs_mean) |&gt;\n  mutate(sc_a_norm_mean = scranton_rad$sc_a_norm_mean)\n # ^ huge discrepancy suggests need to also normalize by land use (and maybe population)\n\nMODIS data was downloaded via AppEEARS. The proportion of land classified as urban and built-up was calculated and applied as a coefficient to the land area, which was then used to normalize the mean radiance. At this point, the analysis was only done for Flagstaff, AZ, and its paired city of Scranton, PA.\n\n# define land cover descriptions\nLand_Cover_Type_1 &lt;- c(\n  \"Water\" = 0, \"Evergreen Needleleaf forest\" = 1, \"Evergreen Broadleaf forest\" = 2,\n  \"Deciduous Needleleaf forest\" = 3, \"Deciduous Broadleaf forest\" = 4, \"Mixed forest\" = 5,\n  \"Closed shrublands\" = 6, \"Open shrublands\" = 7, \"Woody savannas\" = 8, \"Savannas\" = 9,\n  \"Grasslands\" = 10, \"Permanent wetlands\" = 11, \"Croplands\" = 12, \"Urban & built-up\" = 13,\n  \"Cropland/Natural vegetation mosaic\" = 14, \"Snow & ice\" = 15, \"Barren/Sparsely vegetated\" = 16\n)\n\nlcd &lt;- data.frame(\n  ID = Land_Cover_Type_1,\n  landcover = names(Land_Cover_Type_1),\n  stringsAsFactors = FALSE\n)\n\n# calculate urban/built-up area \n\nfs_lulc &lt;- rast(\"data/MCD12Q1.061_LC_Type1_doy2024001000000_aid0001-fs.tif\") |&gt;\n  crop(flagstaff) |&gt;\n  mask(flagstaff)\n\nlevels(fs_lulc) &lt;- lcd\nplot(fs_lulc, main = \"Land Use in Flagstaff, AZ\")\n\n\n\n\n\n\n\nfs_type_summary &lt;- data.frame(values(fs_lulc)) |&gt;\n  drop_na() |&gt;\n  group_by(landcover) |&gt;\n  summarize(tot_pixels = n())\n\nfs_prop_urban &lt;- fs_type_summary[4,2] / sum(fs_type_summary[,2])\nnames(fs_prop_urban) &lt;- \"prop_urban\"\n\nsc_lulc &lt;- rast(\"data/MCD12Q1.061_LC_Type1_doy2024001000000_aid0001-sc.tif\") |&gt;\n  crop(scranton) |&gt;\n  mask(scranton)\nlevels(sc_lulc) &lt;- lcd\nplot(sc_lulc, main = \"Land Use in Scranton, PA\")\n\n\n\n\n\n\n\nsc_type_summary &lt;- data.frame(values(sc_lulc)) |&gt;\n  drop_na() |&gt;\n  group_by(landcover) |&gt;\n  summarize(tot_pixels = n())\n\nsc_prop_urban &lt;- sc_type_summary[4,2] / sum(sc_type_summary[,2])\nnames(sc_prop_urban) &lt;- \"prop_urban\"\n\nThe following chunk works locally but will not render; I’m still figuring this out.\n\n# calculate mean normalized radiance\nflagstaff_urban_km &lt;- (flagstaff$ALAND * fs_prop_urban / 1000^2)[1,1]\nscranton_urban_km &lt;- (scranton$ALAND * sc_prop_urban / 1000^2)[1,1]\n\nscranton_rad &lt;- data.frame(values(scranton_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"rad_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         a_norm_mean = rad_mean / scranton_urban_km, \n         city = \"Scranton\")\n\nflagstaff_rad &lt;- data.frame(values(flagstaff_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"rad_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         a_norm_mean = rad_mean / flagstaff_urban_km,\n         city = \"Flagstaff\")\n\nflagstaff_comp_df &lt;- flagstaff_rad |&gt;\n  bind_rows(scranton_rad)\n\nggplot(flagstaff_comp_df) +\n  geom_line(aes(x = year, y = a_norm_mean)) +\n  facet_wrap(~ city) +\n  labs(x = \"Year\", y = \"Urban Area Normalized Mean Radiance\",\n       title = \"Annual Mean Radiance Normalized by Urban Area\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site hosts the final project for GEO511 Spatial Data Science."
  }
]