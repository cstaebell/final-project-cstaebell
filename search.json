[
  {
    "objectID": "data/Readme.html",
    "href": "data/Readme.html",
    "title": "Data Folder",
    "section": "",
    "text": "Data Folder\nPlace any data needed by your analysis in this folder. Please do not store large files here. Then read in any data using the ‘data’ path. For example, read_csv(\"data/data.csv\")."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Starry Night?",
    "section": "",
    "text": "Electric lights have benefited society immensely since their invention in 1879. Modern work, recreation, and transportation are made possible largely due to artificial lighting. However, when artificial outdoor lighting becomes inefficient and unnecessary, it is known as light pollution, with negative impacts on both wildlife and humans [1].\nConcerns about the effects of light pollution on astronomy led to the 1988 formation of the nonprofit now known as DarkSky International [2]. Since then, DarkSky has grown into a recognized global authority on light pollution with a mission to safeguard communities and wildlife against light pollution [3]. The organization’s International Dark Sky Places program allows communities, parks, and protected areas to seek certification for efforts to preserve and protect their dark skies [4].\nNotably, Flagstaff, Arizona was the first International Dark Sky Place, designated in 2001. As a hub for astronomical observation, the city has been a leader in outdoor lighting policy since 1958 [5]. Other cities, particularly those in the western US, have also recognized the need for measures to combat light pollution, and have achieved DarkSky certification. While certification is certainly not necessary for communities to implement outdoor lighting ordinances and other measures to curb light pollution, it is an indicator of places that have made dark sky conservation a priority.\nThis project aims to explore trends in nighttime light levels first from a national contiguous US perspective, and through more detailed case studies of individual cities."
  },
  {
    "objectID": "index.html#download-and-clean-all-required-data",
    "href": "index.html#download-and-clean-all-required-data",
    "title": "Starry Night?",
    "section": "Download and clean all required data",
    "text": "Download and clean all required data\n\nNational Nighttime Lights\nNASA black marble annual data for 2014 through 2024 were downloaded and saved in a separate script (‘black_marble_data_download.R’). The 2024 nighttime lights across the contiguous US are visualized below.\n\n\nCode\n# Define national spatial extent\nnonconus &lt;- c(\"Guam\", \"Hawaii\", \"Alaska\",\n              \"Commonwealth of the Northern Mariana Islands\",\n              \"United States Virgin Islands\", \"American Samoa\", \"Puerto Rico\")\n\nstates_sf &lt;- states() |&gt;\n  filter(!NAME %in% nonconus) |&gt;\n  select(NAME, geometry) |&gt;\n  st_transform(crs = \"epsg:4326\")\n\nconus &lt;- st_union(states_sf)|&gt;\n  st_as_sf()\n\n# Read in national data for 2024 (to be used for leaflet map later)\npb_download(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_t2024.tif\", \n            repo = \"cstaebell/final-project-cstaebell\")\n\nus_2024_rast &lt;- rast(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_t2024.tif\") |&gt;\n  mask(conus)\n\n\n\n\nCode\nlog_us_2024 &lt;- app(us_2024_rast, fun = log1p)\n\nggplot() +\n  geom_spatraster(data = log_us_2024) + \n  scale_fill_gradient2(low = \"black\",\n                       mid = \"yellow\", \n                       high = \"red\",\n                       midpoint = 4.5,\n                       na.value = \"transparent\") +\n  labs(title = \"Nighttime Lights: 2024\") +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nMean nighttime light radiance for the entire contiguous US is plotted below, where a generally increasing trend can be observed over the past ten years.\n\n\nCode\nyears = 2014:2024\nconus_means = numeric(length(years))\n\nfor (i in 1:length(years)) {\n  pb_download(paste(\"CONUS_VNP46A4_NearNadir_Composite_Snow_Free_qflag_mean_t\",\n                             years[i], \".Rds\", sep = \"\"), repo = \"cstaebell/final-project-cstaebell\")\n  annual_mean &lt;- readRDS(paste(\"CONUS_VNP46A4_NearNadir_Composite_Snow_Free_qflag_mean_t\",\n                             years[i], \".Rds\", sep = \"\")) |&gt;\n    pull(ntl_mean)\n  \n  conus_means[i] &lt;- annual_mean\n}\n\nconus_df &lt;- data.frame(year = years, mean_ntl = conus_means)\n\nggplot(conus_df) +\n  geom_point(aes(x = year, y = mean_ntl)) +\n  geom_smooth(aes(x = year, y = mean_ntl)) +\n  labs(x = \"Year\", y = expression(\"Mean Radiance (nW cm\"^-2~\"sr\"^-1*\")\"),\n       title = \"Annual US Mean Radiance (2014 - 2024)\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\nGetting more granular, we can look at state means.\n\n\nCode\nstate_means &lt;- matrix(nrow = 49, ncol = length(years))\nstate_pixels &lt;- matrix(nrow = 49, ncol = length(years))\n\n# Read in annual data for states and create a single data frame\nfor (i in 1:length(years)) {\n  pb_download(paste(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_mean_t\",\n                             years[i], \".Rds\", sep = \"\"), repo = \"cstaebell/final-project-cstaebell\")\n  annual_mean &lt;- readRDS(paste(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_mean_t\",\n                             years[i], \".Rds\", sep = \"\"))\n  \n  state_means[,i] &lt;- annual_mean[,2]\n  state_pixels[,i] &lt;- annual_mean[,3]\n  \n  # check that state names are ordered the same way for each year\n  if (i == 1) {\n    state_names &lt;- annual_mean[,1]\n  } else {\n    if (sum(state_names != annual_mean[,1]) != 0) {\n      print(\"Different state names\")\n    }\n  }\n}\n\nstate_means_df &lt;- data.frame(state_means)\ncolnames(state_means_df) &lt;- paste(\"ntl_\", years, sep = \"\")\nstate_means_df &lt;- state_means_df |&gt;\n  mutate(state = state_names, \n         pct_change = (ntl_2024 - ntl_2014) / ntl_2014 * 100)\n\n\n# Combine NTL data with geographic data\nstates_ntl &lt;- state_means_df |&gt;\n  inner_join(states_sf, by = c(\"state\" = \"NAME\"))\n\nstates_ntl &lt;- states_sf |&gt;\n  inner_join(state_means_df, by = c(\"NAME\" = \"state\"))\n\n\n\n\nCode\n# Create choropleths\nst_2024_mean_map &lt;- ggplot() +\n  geom_sf(data = filter(states_ntl, NAME != \"District of Columbia\"), aes(fill = ntl_2024)) +\n  labs(title = \"Mean Annual Nighttime Lights by State, 2024\")\n\nst_pct_change_map &lt;- ggplot() + \n  geom_sf(data = states_ntl, aes(fill = pct_change))\n\nst_2024_mean_map / st_pct_change_map\n\n\n\n\n\n\n\n\n\n\n\nCase Studies\nFor case study analyses, population data and local geographies were downloaded from the US Census.\n\n\nCode\n# Download population data\nus_pop &lt;- get_acs(geography = \"place\", state = NULL, \n                  variables = \"B01003_001\", key = census_api_key)\n\naz_pop &lt;- get_acs(geography = \"place\", state = \"AZ\", \n                         variables = \"B01003_001\", key = census_api_key)\n\nil_pop &lt;- get_acs(geography = \"place\", state = \"IL\", \n                         variables = \"B01003_001\", key = census_api_key)\n\ntx_pop &lt;- get_acs(geography = \"place\", state = \"TX\", \n                         variables = \"B01003_001\", key = census_api_key)\n\n# Download local geographies: selected Dark Sky Places\nflagstaff &lt;- places(state = \"AZ\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Flagstaff\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\nhomerglen &lt;- places(state = \"IL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Homer Glen\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\nbeecave &lt;- places(state = \"TX\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Bee Cave\") |&gt;\n  st_transform(crs = \"epsg:4326\") |&gt;\n  left_join(us_pop, by = \"GEOID\")\n\n\nCities of similar population size were found for each selected Dark-Sky community. The city selection process focused on states that do not have laws regarding light pollution or dark sky protection, as compiled by Schultz [6].\n\n\nCode\n# Find suitable comparison cities\nflagstaff_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (flagstaff$estimate - 0.01*flagstaff$estimate) \n                                & estimate &lt;= (flagstaff$estimate + 0.01*flagstaff$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\nhomerglen_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (homerglen$estimate - 0.005*homerglen$estimate) \n                                & estimate &lt;= (homerglen$estimate + 0.005*homerglen$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\nbeecave_sim_pop &lt;- us_pop |&gt; filter(estimate &gt;= (beecave$estimate - 0.005*beecave$estimate) \n                                & estimate &lt;= (beecave$estimate + 0.005*beecave$estimate)) |&gt;\n  separate(NAME, into = c(\"city\", \"state\"), sep = \", \")\n\n# Download/process comparison city data\n # Flagstaff counterpart\nscranton &lt;- places(state = \"PA\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Scranton\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\n # Homer Glen counterpart\nbelvidere &lt;- places(state = \"IL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Belvidere\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\n # Bee Cave counterpart\nclanton &lt;- places(state = \"AL\", cb = TRUE, year = 2024) |&gt;\n  filter(NAME == \"Clanton\") |&gt;\n  left_join(us_pop, by = \"GEOID\") |&gt;\n  st_transform(crs = \"epsg:4326\")\n\n\n\n\nCode\n# Subset rasters to each area \ncities &lt;- list(flagstaff, homerglen, beecave, scranton, belvidere, clanton)\ncity_rasters &lt;- vector(\"list\", length = length(cities))\n\n# Load files for each year\nfor (i in 1:length(years)){\n  pb_download(paste(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_t\", \n                     years[i], \".tif\", sep = \"\"), repo = \"cstaebell/final-project-cstaebell\")\n  rast_file &lt;- paste(\"US_VNP46A4_NearNadir_Composite_Snow_Free_qflag_t\", \n                     years[i], \".tif\", sep = \"\")\n  \n  year_rast &lt;- rast(rast_file)\n  \n  # Loop over cities\n  for (j in 1:length(cities)) {\n    # Crop and mask to city extent\n    current_rast &lt;- year_rast |&gt;\n      terra::crop(cities[[j]]) |&gt;\n      mask(cities[[j]])\n    \n    # Create list entry during first iteration, then append in subsequent iterations\n    if (i == 1) {\n    city_rasters[[j]] &lt;- list(current_rast)\n    } else {\n    city_rasters[[j]][[length(city_rasters[[j]]) + 1]] &lt;- current_rast\n    }\n  }\n}\n\n\nℹ All local files already up-to-date!\n\n\nCode\n# Stack city lists \ncity_rasters &lt;- lapply(city_rasters, rast)\n\n# Create separate rasters for each city\ncity_var_names &lt;- paste0(c(\"flagstaff\", \"homerglen\", \"beecave\", \"scranton\", \n                           \"belvidere\", \"clanton\"), \"_rast\")\nfor (c in 1:length(city_var_names)) {\n  assign(city_var_names[c], city_rasters[[c]])\n}\n\n# Calculate annual means\nannual_means &lt;- vector(\"list\", length = length(cities))\nfor (i in 1:length(city_rasters)) {\n  ntl_vals &lt;- data.frame(values(city_rasters[[i]])) |&gt;\n    summarize(across(t2014:t2024, ~ mean(.x, na.rm = TRUE)))\n  \n  annual_means[[i]] &lt;- ntl_vals\n}\n\n# Create mean dataframes for each city\ncity_df_var_names &lt;- paste0(c(\"flagstaff\", \"homerglen\", \"beecave\", \"scranton\", \n                           \"belvidere\", \"clanton\"), \"_means\")\nfor (i in 1:length(annual_means)) {\n  df &lt;- annual_means[[i]] |&gt;\n    pivot_longer(cols = t2014:t2024) |&gt;\n    mutate(name = years) |&gt;\n    rename(year = name, mean_ntl = value)\n  \n  assign(city_df_var_names[i], df)\n}\n\n\nSimply looking at annual means for each city is more of a proxy for overall development than it is for lighting policy. Therefore, we need to look at land use and only compare the urban and built-up areas.\n\n\nCode\n# Annual means\nfs_means &lt;- ggplot() +\n  geom_line(data = flagstaff_means, aes(x = year, y = mean_ntl), color = \"blue\") +\n  geom_line(data = scranton_means, aes(x = year, y = mean_ntl), color = \"red\") +\n  labs(x = \"Year\", y = \"Mean NTL\", title = \"Flagstaff and Scranton Annual Mean Nighttime Lights\")\n\nhb_means &lt;- ggplot() +\n  geom_line(data = homerglen_means, aes(x = year, y = mean_ntl), color = \"blue\") +\n  geom_line(data = belvidere_means, aes(x = year, y = mean_ntl), color = \"red\") +\n  labs(x = \"Year\", y = \"Mean NTL\", title = \"Homer Glen and Belvidere Annual Mean Nighttime Lights\")\n\nbc_means &lt;- ggplot() +\n  geom_line(data = beecave_means, aes(x = year, y = mean_ntl), color = \"blue\") +\n  geom_line(data = clanton_means, aes(x = year, y = mean_ntl), color = \"red\") +\n  labs(x = \"Year\", y = \"Mean NTL\", title = \"Bee Cave and Clanton Annual Mean Nighttime Lights\")\n\nfs_means + hb_means + bc_means\n\n\n\n\n\n\n\n\n\n\n\nCode\n# calculate mean normalized radiance\nflagstaff_area_km &lt;- flagstaff$ALAND / 1000^2\nscranton_area_km &lt;- scranton$ALAND / 1000^2\n\nscranton_rad &lt;- data.frame(values(scranton_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"sc_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         sc_a_norm_mean = sc_mean / scranton_area_km)\n\n\nMODIS data was downloaded via AppEEARS. The proportion of land classified as urban and built-up was calculated and applied as a coefficient to the land area, which was then used to normalize the mean radiance. At this point, the analysis was only done for Flagstaff, AZ, and its paired city of Scranton, PA.\n\n\nCode\n# define land cover descriptions\nLand_Cover_Type_1 &lt;- c(\n  \"Water\" = 0, \"Evergreen Needleleaf forest\" = 1, \"Evergreen Broadleaf forest\" = 2,\n  \"Deciduous Needleleaf forest\" = 3, \"Deciduous Broadleaf forest\" = 4, \"Mixed forest\" = 5,\n  \"Closed shrublands\" = 6, \"Open shrublands\" = 7, \"Woody savannas\" = 8, \"Savannas\" = 9,\n  \"Grasslands\" = 10, \"Permanent wetlands\" = 11, \"Croplands\" = 12, \"Urban & built-up\" = 13,\n  \"Cropland/Natural vegetation mosaic\" = 14, \"Snow & ice\" = 15, \"Barren/Sparsely vegetated\" = 16\n)\n\nlcd &lt;- data.frame(\n  ID = Land_Cover_Type_1,\n  landcover = names(Land_Cover_Type_1),\n  stringsAsFactors = FALSE\n)\n\n# calculate urban/built-up area \n\nfs_lulc &lt;- rast(\"data/MCD12Q1.061_LC_Type1_doy2024001000000_aid0001-fs.tif\") |&gt;\n  crop(flagstaff) |&gt;\n  mask(flagstaff)\n\nlevels(fs_lulc) &lt;- lcd\nplot(fs_lulc, main = \"Land Use in Flagstaff, AZ\")\n\n\n\n\n\n\n\n\n\nCode\nfs_type_summary &lt;- data.frame(values(fs_lulc)) |&gt;\n  drop_na() |&gt;\n  group_by(landcover) |&gt;\n  summarize(tot_pixels = n())\n\nfs_prop_urban &lt;- fs_type_summary[4,2] / sum(fs_type_summary[,2])\nnames(fs_prop_urban) &lt;- \"prop_urban\"\n\nsc_lulc &lt;- rast(\"data/MCD12Q1.061_LC_Type1_doy2024001000000_aid0001-sc.tif\") |&gt;\n  crop(scranton) |&gt;\n  mask(scranton)\nlevels(sc_lulc) &lt;- lcd\nplot(sc_lulc, main = \"Land Use in Scranton, PA\")\n\n\n\n\n\n\n\n\n\nCode\nsc_type_summary &lt;- data.frame(values(sc_lulc)) |&gt;\n  drop_na() |&gt;\n  group_by(landcover) |&gt;\n  summarize(tot_pixels = n())\n\nsc_prop_urban &lt;- sc_type_summary[4,2] / sum(sc_type_summary[,2])\nnames(sc_prop_urban) &lt;- \"prop_urban\"\n\n\nThe following chunk works locally but will not render; I’m still figuring this out.\n\n\nCode\n# calculate mean normalized radiance\nflagstaff_urban_km &lt;- (flagstaff$ALAND * fs_prop_urban / 1000^2)[1,1]\nscranton_urban_km &lt;- (scranton$ALAND * sc_prop_urban / 1000^2)[1,1]\n\nscranton_rad &lt;- data.frame(values(scranton_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"rad_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         a_norm_mean = rad_mean / scranton_urban_km, \n         city = \"Scranton\")\n\nflagstaff_rad &lt;- data.frame(values(flagstaff_bm_rast)) |&gt;\n  summarize(across(t2012:t2024, mean, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = t2012:t2024, names_to = \"year\", values_to = \"rad_mean\") |&gt;\n  mutate(year = as.integer(sub(\"t\", \"\", year)),\n         a_norm_mean = rad_mean / flagstaff_urban_km,\n         city = \"Flagstaff\")\n\nflagstaff_comp_df &lt;- flagstaff_rad |&gt;\n  bind_rows(scranton_rad)\n\nggplot(flagstaff_comp_df) +\n  geom_line(aes(x = year, y = a_norm_mean)) +\n  facet_wrap(~ city) +\n  labs(x = \"Year\", y = \"Urban Area Normalized Mean Radiance\",\n       title = \"Annual Mean Radiance Normalized by Urban Area\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site hosts the final project for GEO511 Spatial Data Science."
  }
]